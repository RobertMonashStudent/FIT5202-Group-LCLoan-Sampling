{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "* [Read-CSV](#Read-CSV)\n",
    "* [Categorical-variables-handling](#Categorical-variables-handling)\n",
    "* [Numeric-variables-handing](#Numeric-variables-handing)\n",
    "* [Pipeline-to-process-all-variables](#Pipeline-to-process-all-variables)\n",
    "* [Create-features-and-label](#Create-features-and-label)\n",
    "* [Split-training-set-and-test-set](#Split-training-set-and-test-set)\n",
    "* [Logistic-Regression-fitting](#Logistic-Regression-fitting)\n",
    "* [Hyper-parameter-tunning-for-logistic-regression](#Hyper-parameter-tunning-for-logistic-regression)\n",
    "* [Decision-Tree-fitting](#Decision-Tree-fitting)\n",
    "* [Random-Forest-fitting](#Random-Forest-fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.StringIndexer\n",
       "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.feature.StandardScaler\n",
       "import org.apache.spark.mllib.feature.Normalizer\n",
       "import org.apache.spark.ml.feature.VectorAssembler\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.sql._\n"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.StandardScaler\n",
    "import org.apache.spark.mllib.feature.Normalizer\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.sql._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV\n",
    "\n",
    "Also invert the label\n",
    "* 1: bad loan\n",
    "* 0: good loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invertLabel: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,Some(List(IntegerType)))\n"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val invertLabel = udf((v: Int) => v match {\n",
    "    case 0 => 1\n",
    "    case 1 => 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [loan_amnt: int, term: string ... 63 more fields]\n"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"LCLoan_Wrangled.csv\")\n",
    "  .withColumn(\"loan_status\",invertLabel($\"loan_status\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical variables handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categoricalColumns: Array[String] = Array(term, grade, sub_grade, emp_title, emp_length, home_ownership, verification_status, issue_d, purpose, title, zip_code, addr_state, earliest_cr_line, initial_list_status, last_pymnt_d, last_credit_pull_d, application_type)\n"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val categoricalColumns = df.dtypes.filter(column => column._2 == \"StringType\").map(_._1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categoricalFeatures: Array[org.apache.spark.ml.Estimator[_ >: org.apache.spark.ml.feature.OneHotEncoderModel with org.apache.spark.ml.feature.StringIndexerModel <: org.apache.spark.ml.Model[_ >: org.apache.spark.ml.feature.OneHotEncoderModel with org.apache.spark.ml.feature.StringIndexerModel <: org.apache.spark.ml.Transformer with org.apache.spark.ml.param.shared.HasHandleInvalid with org.apache.spark.ml.util.MLWritable] with org.apache.spark.ml.param.shared.HasHandleInvalid with org.apache.spark.ml.util.MLWritable] with org.apache.spark.ml.param.shared.HasHandleInvalid with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.Estimator[_ >: org.apache.spark.ml.feature.OneHotEncoderModel with org.apache.spark.ml.feature..."
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val categoricalFeatures = categoricalColumns.flatMap{ name =>\n",
    "    \n",
    "    val stringIndexer = new StringIndexer()\n",
    "      .setInputCol(name)\n",
    "      .setOutputCol(name + \"_index\")\n",
    "      .setHandleInvalid(\"keep\")\n",
    "    \n",
    "    val oneHotEncoder = new OneHotEncoderEstimator()\n",
    "      .setInputCols(Array(name + \"_index\"))\n",
    "      .setOutputCols(Array(name + \"_vec\"))\n",
    "      .setDropLast(false)\n",
    "    \n",
    "    Array(stringIndexer, oneHotEncoder)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Numeric variables handing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numericColumns: Array[String] = Array(loan_amnt, int_rate, annual_inc, dti, delinq_2yrs, inq_last_6mths, open_acc, pub_rec, revol_bal, revol_util, total_acc, out_prncp, total_pymnt, total_rec_int, total_rec_late_fee, collection_recovery_fee, last_pymnt_amnt, collections_12_mths_ex_med, policy_code, acc_now_delinq, tot_coll_amt, tot_cur_bal, total_rev_hi_lim, acc_open_past_24mths, chargeoff_within_12_mths, delinq_amnt, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mort_acc, mths_since_recent_bc, num_accts_ever_120_pd, num_actv_rev_tl, num_bc_sats, num_il_tl, num_rev_accts, num_sats, num_tl_120dpd_2m, num_tl_90g_dpd_24m, num_tl_op_past_12m, pct_tl_nvr_dlq, percent_bc_gt_75, pub_rec_bankruptcies, tax_liens, tot_hi_cred_lim, total_il_high_credit_limit, loa..."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numericColumns = df.dtypes.filter(column => column._2 == \"IntegerType\" || column._2 == \"DoubleType\").map(_._1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numericColumnsAssembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_4660d8d961f4\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numericColumnsAssembler = new VectorAssembler()\n",
    "  .setInputCols(numericColumns)\n",
    "  .setOutputCol(\"numerical_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numericColumnsScaler: org.apache.spark.ml.feature.StandardScaler = stdScal_c1fd62652589\n"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numericColumnsScaler = new StandardScaler()\n",
    "      .setInputCol(\"numerical_features\")\n",
    "      .setOutputCol(\"numerical_features\" + \"_vec\")\n",
    "      .setWithStd(true)\n",
    "      .setWithMean(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to process all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_643c7147b130\n",
       "df_transformed: org.apache.spark.sql.DataFrame = [loan_amnt: int, term: string ... 99 more fields]\n"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline()\n",
    "  .setStages(categoricalFeatures ++ Array(numericColumnsAssembler,numericColumnsScaler) )\n",
    "\n",
    "val df_transformed = pipeline\n",
    "  .fit(df)\n",
    "  .transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureColumns: Array[String] = Array(term_vec, grade_vec, sub_grade_vec, emp_title_vec, emp_length_vec, home_ownership_vec, verification_status_vec, issue_d_vec, purpose_vec, title_vec, zip_code_vec, addr_state_vec, earliest_cr_line_vec, initial_list_status_vec, last_pymnt_d_vec, last_credit_pull_d_vec, application_type_vec, numerical_features_vec)\n"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureColumns = df_transformed.columns.filter(_.contains(\"_vec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureColumnsAssembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_bc5d983169de\n",
       "df_input: org.apache.spark.sql.DataFrame = [loan_amnt: int, term: string ... 101 more fields]\n"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureColumnsAssembler = new VectorAssembler()\n",
    "  .setInputCols(featureColumns)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val df_input = featureColumnsAssembler.transform(df_transformed).withColumn(\"label\",col(\"loan_status\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [loan_amnt: int, term: string ... 101 more fields]\n",
       "testData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [loan_amnt: int, term: string ... 101 more fields]\n"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trainingData, testData) = df_input.randomSplit(Array(0.9, 0.1), seed = 1234L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res58: Long = 1997\n"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res59: Long = 18073\n"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_30a0562d0fe0\n"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LogisticRegression()\n",
    "//   .setMaxIter(100)\n",
    "//   .setRegParam(0.3)\n",
    "//   .setElasticNetParam(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lrModel: org.apache.spark.ml.classification.LogisticRegressionModel = LogisticRegressionModel: uid = logreg_30a0562d0fe0, numClasses = 2, numFeatures = 10857\n"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Fit the model\n",
    "val lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainingSummary: org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummaryImpl@4062040f\n",
       "accuracy: Double = 1.0\n",
       "falsePositiveRate: Double = 0.0\n",
       "truePositiveRate: Double = 1.0\n",
       "fMeasure: Double = 1.0\n",
       "precision: Double = 1.0\n",
       "recall: Double = 1.0\n"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Extract the summary from the returned LogisticRegressionModel instance trained in the earlier\n",
    "// example\n",
    "val trainingSummary = lrModel.binarySummary\n",
    "val accuracy = trainingSummary.accuracy\n",
    "val falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "val truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "val fMeasure = trainingSummary.weightedFMeasure\n",
    "val precision = trainingSummary.weightedPrecision\n",
    "val recall = trainingSummary.weightedRecall\n",
    "println(s\"Accuracy: $accuracy\\nFPR: $falsePositiveRate\\nTPR: $truePositiveRate\\n\" +\n",
    "  s\"F-measure: $fMeasure\\nPrecision: $precision\\nRecall: $recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                 FPR|                TPR|\n",
      "+--------------------+-------------------+\n",
      "|                 0.0|                0.0|\n",
      "|                 0.0|0.17706666666666668|\n",
      "|                 0.0|0.27413333333333334|\n",
      "|                 0.0|             0.3696|\n",
      "|                 0.0| 0.4650666666666667|\n",
      "|                 0.0| 0.5605333333333333|\n",
      "|                 0.0|              0.656|\n",
      "|                 0.0| 0.7514666666666666|\n",
      "|                 0.0| 0.8469333333333333|\n",
      "|                 0.0|             0.9424|\n",
      "|0.004383257192245956|                1.0|\n",
      "|0.015434004198049142|                1.0|\n",
      "|0.026484751203852328|                1.0|\n",
      "|0.037535498209655516|                1.0|\n",
      "|  0.0485862452154587|                1.0|\n",
      "|0.059636992221261884|                1.0|\n",
      "| 0.07068773922706507|                1.0|\n",
      "| 0.08173848623286825|                1.0|\n",
      "| 0.09278923323867144|                1.0|\n",
      "| 0.10383998024447463|                1.0|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.9998737621928633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "roc: org.apache.spark.sql.DataFrame = [FPR: double, TPR: double]\n"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val roc = trainingSummary.roc\n",
    "roc.show()\n",
    "println(s\"areaUnderROC: ${trainingSummary.areaUnderROC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc.createOrReplaceTempView(\"roc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K     |################################| 10.1MB 30.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2011k (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K     |################################| 512kB 42.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.0)\n",
      "Collecting numpy>=1.12.0 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |######################          | 12.1MB 43.4MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |################################| 17.3MB 43.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.16.4 pandas-0.24.2 pytz-2019.1\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/83/d989ee20c78117c737ab40e0318ea221f1aed4e3f5a40b4f93541b369b93/matplotlib-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K     |################################| 13.1MB 21.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K     |################################| 92kB 27.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
      "\u001b[K     |################################| 71kB 27.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from kiwisolver>=1.0.1->matplotlib) (39.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib) (1.11.0)\n",
      "Installing collected packages: kiwisolver, cycler, pyparsing, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.0 pyparsing-2.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FPR       TPR\n",
      "0  0.0  0.000000\n",
      "1  0.0  0.177067\n",
      "2  0.0  0.274133\n",
      "3  0.0  0.369600\n",
      "4  0.0  0.465067\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from IPython.display import Image\n",
    "\n",
    "roc = spark.sql(\"select * from roc\")\n",
    "rocPandas = roc.toPandas()\n",
    "print(rocPandas.head())\n",
    "plt.clf()\n",
    "plt.plot(rocPandas['FPR'],rocPandas['TPR'])\n",
    "with tempfile.NamedTemporaryFile(suffix=\".png\") as fo:\n",
    "    plt.savefig(fo.name)\n",
    "    retval = Image(filename=fo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction: org.apache.spark.sql.DataFrame = [loan_amnt: int, term: string ... 104 more fields]\n"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prediction = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluatePrediction: (prediction: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluatePrediction(prediction: DataFrame) = {\n",
    "    prediction.createOrReplaceTempView(\"prediction\")\n",
    "    \n",
    "    spark.sql(\"\"\"\n",
    "select label,prediction,count(1) from prediction group by label,prediction\n",
    "\"\"\").show(false)\n",
    "    \n",
    "    spark.sql(\"\"\"\n",
    "select \n",
    "(TP+TN)/(P+N) as Accuracy,\n",
    "TP/(TP+FP) as Precision,\n",
    "TP/(TP+FN) as Recall,\n",
    "2*TP/(2*TP+FP+FN) as F1\n",
    "from (\n",
    "    select \n",
    "    count(1) as total, \n",
    "    sum(case when label = 1 and prediction = 1 then 1 else 0 end) as TP,\n",
    "    sum(case when label = 0 and prediction = 0 then 1 else 0 end) as TN,\n",
    "    sum(case when label = 0 and prediction = 1 then 1 else 0 end) as FP,\n",
    "    sum(case when label = 1 and prediction = 0 then 1 else 0 end) as FN,\n",
    "    sum(case when label = 1 then 1 else 0 end) as P,\n",
    "    sum(case when label = 0 then 1 else 0 end) as N\n",
    "    from prediction\n",
    "    )\n",
    "\"\"\").show(false)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------+\n",
      "|label|prediction|count(1)|\n",
      "+-----+----------+--------+\n",
      "|0    |0.0       |1786    |\n",
      "|1    |1.0       |211     |\n",
      "+-----+----------+--------+\n",
      "\n",
      "+--------+---------+------+---+\n",
      "|Accuracy|Precision|Recall|F1 |\n",
      "+--------+---------+------+---+\n",
      "|1.0     |1.0      |1.0   |1.0|\n",
      "+--------+---------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluatePrediction(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.DecisionTreeClassificationModel\n",
       "import org.apache.spark.ml.classification.DecisionTreeClassifier\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "dt: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_07c32a49c1e9\n"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.DecisionTreeClassificationModel\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassifier\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "val dt = new DecisionTreeClassifier()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-04 11:40:16,677 WARN  [Executor task launch worker for task 2330] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_2706_1 in memory! (computed 140.4 MB so far)\n",
      "2019-06-04 11:40:16,677 WARN  [Executor task launch worker for task 2330] storage.BlockManager (Logging.scala:logWarning(66)) - Persisting block rdd_2706_1 to disk instead.\n",
      "2019-06-04 11:40:18,338 WARN  [Executor task launch worker for task 2329] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_2706_0 in memory! (computed 210.9 MB so far)\n",
      "2019-06-04 11:40:18,338 WARN  [Executor task launch worker for task 2329] storage.BlockManager (Logging.scala:logWarning(66)) - Persisting block rdd_2706_0 to disk instead.\n",
      "2019-06-04 11:40:20,769 WARN  [Executor task launch worker for task 2330] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_2706_1 in memory! (computed 210.9 MB so far)\n",
      "2019-06-04 11:40:24,115 WARN  [Executor task launch worker for task 2329] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_2706_0 in memory! (computed 316.5 MB so far)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.classification.DecisionTreeClassificationModel = DecisionTreeClassificationModel (uid=dtc_07c32a49c1e9) of depth 1 with 3 nodes\n",
       "prediction: org.apache.spark.sql.DataFrame = [loan_amnt: int, term: string ... 104 more fields]\n"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = dt.fit(trainingData)\n",
    "val prediction = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------+\n",
      "|label|prediction|count(1)|\n",
      "+-----+----------+--------+\n",
      "|0    |0.0       |1786    |\n",
      "|1    |1.0       |211     |\n",
      "+-----+----------+--------+\n",
      "\n",
      "+--------+---------+------+---+\n",
      "|Accuracy|Precision|Recall|F1 |\n",
      "+--------+---------+------+---+\n",
      "|1.0     |1.0      |1.0   |1.0|\n",
      "+--------+---------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluatePrediction(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_765948292ea5\n"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setNumTrees(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-04 11:43:08,874 WARN  [Executor task launch worker for task 3021] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_1 in memory! (computed 142.9 MB so far)\n",
      "2019-06-04 11:43:08,874 WARN  [Executor task launch worker for task 3021] storage.BlockManager (Logging.scala:logWarning(66)) - Persisting block rdd_3093_1 to disk instead.\n",
      "2019-06-04 11:43:10,710 WARN  [Executor task launch worker for task 3020] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_0 in memory! (computed 214.8 MB so far)\n",
      "2019-06-04 11:43:10,711 WARN  [Executor task launch worker for task 3020] storage.BlockManager (Logging.scala:logWarning(66)) - Persisting block rdd_3093_0 to disk instead.\n",
      "2019-06-04 11:43:12,484 WARN  [Executor task launch worker for task 3021] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_1 in memory! (computed 214.8 MB so far)\n",
      "2019-06-04 11:43:15,942 WARN  [Executor task launch worker for task 3020] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_0 in memory! (computed 322.3 MB so far)\n",
      "2019-06-04 11:43:18,153 WARN  [Executor task launch worker for task 3025] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_1 in memory! (computed 142.9 MB so far)\n",
      "2019-06-04 11:43:18,303 WARN  [Executor task launch worker for task 3024] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_0 in memory! (computed 214.8 MB so far)\n",
      "2019-06-04 11:43:21,062 WARN  [Executor task launch worker for task 3029] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_1 in memory! (computed 142.9 MB so far)\n",
      "2019-06-04 11:43:21,592 WARN  [Executor task launch worker for task 3028] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_0 in memory! (computed 214.8 MB so far)\n",
      "2019-06-04 11:43:25,425 WARN  [Executor task launch worker for task 3033] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_1 in memory! (computed 142.9 MB so far)\n",
      "2019-06-04 11:43:25,566 WARN  [Executor task launch worker for task 3032] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_0 in memory! (computed 214.8 MB so far)\n",
      "2019-06-04 11:43:29,781 WARN  [Executor task launch worker for task 3037] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_1 in memory! (computed 142.9 MB so far)\n",
      "2019-06-04 11:43:29,943 WARN  [Executor task launch worker for task 3036] memory.MemoryStore (Logging.scala:logWarning(66)) - Not enough space to cache rdd_3093_0 in memory! (computed 214.8 MB so far)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_765948292ea5) with 100 trees\n",
       "prediction: org.apache.spark.sql.DataFrame = [loan_amnt: int, term: string ... 104 more fields]\n"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = rf.fit(trainingData)\n",
    "val prediction = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------+\n",
      "|label|prediction|count(1)|\n",
      "+-----+----------+--------+\n",
      "|1    |0.0       |211     |\n",
      "|0    |0.0       |1786    |\n",
      "+-----+----------+--------+\n",
      "\n",
      "+------------------+---------+------+---+\n",
      "|Accuracy          |Precision|Recall|F1 |\n",
      "+------------------+---------+------+---+\n",
      "|0.8943415122684026|null     |0.0   |0.0|\n",
      "+------------------+---------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluatePrediction(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
